{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from rdflib import Literal, RDF, URIRef\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import rdflib.namespace\n",
    "\n",
    "from owlready2 import *\n",
    "from owlready2 import get_ontology\n",
    "\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('opioids_data_original.xlsx')\n",
    "side_effects = pd.read_excel(\"sider_output.xlsx\")\n",
    "frequencies = pd.read_csv('meddra_freq.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of different outcome labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outcome.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the 'Outcome' column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'] = data['Outcome'].replace(['Outcome niet ingevuld', 'Recovered/resolved', 'Not recovered/not resolved/ongoing', 'Recovered/resolved with sequelae', 'Recovering/resolving'], ['Unknown', 'Recovered', 'Ongoing', 'Sequelae', 'Recovering'])\n",
    "data.Outcome.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MISSING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DROP COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Primary Source Description', 'Status', 'Category', 'OutcomeCodeSystemVersion', 'OutcomeText', 'CultureID', 'date_received', 'summary', 'narrative', 'IsCurrent', 'IsDefaultSOC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMOVE OUTLIERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removal of instances with bodyweight == 0 \n",
    "- Removal of instances with height == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.BodyWeight != 0] \n",
    "data = data[data.Height != 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tramadol met paracetamol; N02AJ13 --> N02AX02\n",
    "oxy met nalo; N02AA55 --> N02AA05\n",
    "morf combi; N02AA51 --> N02AA01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ATCText'].replace(['TRAMADOL MET PARACETAMOL', 'OXYCODON MET NALOXON', 'MORFINE, COMBINATIEPREPARATEN'], ['TRAMADOL', 'OXYCODON', 'MORFINE'], inplace=True)\n",
    "\n",
    "data['ATCode'].replace(['N02AJ13', 'N02AA51'], ['N02AX02', 'N02AA01'], inplace=True)\n",
    "\n",
    "data['ATCText'] = data['ATCText'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MERGING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(side_effects[['ATCode', 'ATCText', 'PTCode', 'Side effect', 'Frequency']], how='left', on=['ATCode', 'ATCText', 'PTCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'reaction_impact' column presumably measures the impact the medicine has had on the patient. As shown before, there is no reaction_impact for fatalities. \n",
    "We can impute the missing values by taking the average of a patient with similar features. \n",
    "\n",
    "To make this easier, we'll first create a column to bin the ages. We'll also create a BMI column and a weight group column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_group'] = pd.cut(x=data['age_year'], bins=[18, 24, 44, 64, 90])\n",
    "data['BMI'] = data['BodyWeight'] / (data['Height']/100)**2\n",
    "data['weight_group'] = pd.cut(x=data['BMI'], bins=[0, 18.5, 25, 30, 50], labels=['underweight', 'normal', 'overweight', 'obese'])\n",
    "data['WorldwideUniqueCaseIdentification'] = data['WorldwideUniqueCaseIdentification'].str.replace(\" \", \"\")\n",
    "data['age_group'] = data['age_group'].astype(str)\n",
    "data['PTCode'] = data['PTCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Frequency'] = data['Frequency'] * 100\n",
    "data['Frequency'] = data['Frequency'].replace(0.0, 0.0001)\n",
    "data['Frequency'] = data['Frequency'].fillna(0.0)\n",
    "\n",
    "data['is_sideeffect'] = data['Side effect'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdn = list(data['GenericDrugName'].str.split(' ', expand=True).stack().unique())\n",
    "type = ['CAPSULE', 'NEUSSPRAY', 'TABLET', 'PLEISTER', 'INJVLST', 'ZETPIL', 'DRANK', 'SPRAY', 'ZUIGTABLET', 'BRUISTABLET', 'INJ/INFOPL', 'INFVLST', 'DRUPPELS', 'SMELTTABLET', 'INJECTIE/INFUUS', 'DISPERTABLET', 'TAB', 'INJECTIEPOEDER']\n",
    "dosage = []\n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "for i in gdn:\n",
    "    if has_numbers(i):\n",
    "        dosage.append(i)\n",
    "\n",
    "data['Type'] = data['GenericDrugName'].apply(lambda x : ''.join([k for k in str(x).split() if k in type]))\n",
    "data['Dosage'] = data['GenericDrugName'].apply(lambda x : ''.join([k for k in str(x).split() if k in dosage]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sideeffects = pd.read_excel(\"sider_output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols1 = [\"-\", \"_\", \"\\+\", \"\\?\", \"%\", \"\\*\", \"\\.\", \"\\,\", \"\\:\", \"\\;\", \"\\!\", \"\\@\", \"\\#\", \"\\$\", \"\\^\", \"\\&\", \"\\(\", \"\\)\", \"\\{\", \"\\}\", \"\\[\", \"\\]\", \"\\|\", \"\\/\", \"\\~\", \"\\`\", \"\\=\", \"\\<\", \"\\>\", \" \"]\n",
    "symbols2 = [\"NAN\", \"NaN\", \"None\", \"NaT\", \"NAT\", \"nat\", \"n/a\", \"N/A\", \"n/a\", \"N/A\", \"n.a.\", \"N.A.\", \" \"]\n",
    "\n",
    "\n",
    "for i in symbols1:\n",
    "    data = data.replace(i, \"\", regex = True)\n",
    "    data_sideeffects = data_sideeffects.replace(i, \"\", regex = True)\n",
    "\n",
    "for i in symbols2:\n",
    "    \n",
    "    # replace symbol in string with \"\", bit not the whole string\n",
    "    data = data.replace(rf'\\b{i}\\b', np.nan, regex = True)\n",
    "    data_sideeffects = data_sideeffects.replace(rf'\\b{i}\\b', np.nan, regex = True)\n",
    "\n",
    "data\n",
    "data_sideeffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"opioid_datamerged.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"http://example.org/medsur.owl\")\n",
    "\n",
    "class Patients(Thing):\n",
    "    namespace = onto\n",
    "\n",
    "class AgeGroup(Thing):\n",
    "    namespace = onto\n",
    " \n",
    "class hasAgeGroup(ObjectProperty):                 \n",
    "    domain = [Patients]\n",
    "    range = [AgeGroup]\n",
    "    namespace = onto\n",
    "  \n",
    "class WeightGroup(Thing):\n",
    "    namespace = onto\n",
    "    \n",
    "class hasWeightGroup(ObjectProperty):   \n",
    "    domain = [Patients]\n",
    "    range = [WeightGroup]\n",
    "    namespace = onto\n",
    "    \n",
    "class Symptoms(Thing):\n",
    "    namespace = onto\n",
    "    \n",
    "class hasSymptom(ObjectProperty):\n",
    "    domain = [Patients]\n",
    "    range = [Symptoms]\n",
    "    namespace = onto\n",
    "\n",
    "class Outcome(Thing):\n",
    "    namespace = onto\n",
    "    \n",
    "class hasOutcome(ObjectProperty):\n",
    "    domain = [Patients]\n",
    "    range = [Outcome]\n",
    "    namespace = onto\n",
    "    \n",
    "class Gender(Thing):\n",
    "    namespace = onto\n",
    "\n",
    "class hasGender(ObjectProperty):\n",
    "    domain = [Patients]\n",
    "    range = [Gender]\n",
    "    namespace = onto\n",
    "\n",
    "class Drug(Thing):\n",
    "    namespace = onto\n",
    "    \n",
    "class IsGivenDrug(ObjectProperty):\n",
    "    domain = [Patients]\n",
    "    range = [Drug]\n",
    "    namespace = onto\n",
    "    \n",
    "class IsOfDosis(ObjectProperty):\n",
    "    domain = [Drug]\n",
    "    namespace = onto\n",
    "    \n",
    "class IsOfType(ObjectProperty):\n",
    "    domain = [Drug]\n",
    "    namespace = onto\n",
    "\n",
    "class SideEffects(Thing):\n",
    "    namespace = onto\n",
    "    \n",
    "class hasSideEffect(ObjectProperty):\n",
    "    domain = [Drug]\n",
    "    range = [SideEffects]\n",
    "    namespace = onto\n",
    "    \n",
    "class hasFrequency(ObjectProperty):                 \n",
    "    domain = [SideEffects]\n",
    "    namespace = onto \n",
    "    \n",
    "class suffersSideEffects(ObjectProperty):\n",
    "    domain = [Patients]\n",
    "    range = [SideEffects]\n",
    "    namespace = onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.save(file = \"medsur.rdf\", format = \"rdfxml\") \n",
    "g = rdflib.Graph()\n",
    "g.parse(\"medsur.rdf\", format=\"xml\")\n",
    "\n",
    "# Loop through each triple in the graph (subj, pred, obj)\n",
    "for subj, pred, obj in g:\n",
    "    \n",
    "    # Check if there is at least one triple in the Graph\n",
    "    if (subj, pred, obj) not in g:\n",
    "       raise Exception(\"It better be!\")\n",
    "\n",
    "# Print the number of \"triples\" in the Graph\n",
    "print(f\"Graph g has {len(g)} statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the triples in the graph \n",
    "for s, p, o in g:\n",
    "    print(s, p, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add RDF triples to the ontology\n",
    "EX = rdflib.Namespace(\"http://example.org/medsur.rdf#\")\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    patient = URIRef(f\"http://www.medsur.org/patient_{row['WorldwideUniqueCaseIdentification']}\")\n",
    "    g.add((patient, RDF.type, EX.Patients))\n",
    "\n",
    "    weight_group = URIRef(f\"http://www.medsur.org/weight/{row['weight_group']}\")\n",
    "    g.add((weight_group, RDF.type, EX.WeightGroup))\n",
    "    g.add((patient, EX.hasWeightGroup, weight_group))\n",
    "\n",
    "    if float(row[\"age_year\"]) >= 65:\n",
    "        agegroup = URIRef(\"http://www.medsur.org/age/65_above\")\n",
    "    elif float(row[\"age_year\"]) >= 45:\n",
    "        agegroup = URIRef(\"http://www.medsur.org/age/45_64\") \n",
    "    elif float(row[\"age_year\"]) >= 25:\n",
    "        agegroup = URIRef(\"http://www.medsur.org/age/25_44\")\n",
    "    elif float(row[\"age_year\"]) >= 18:\n",
    "        agegroup = URIRef(\"http://www.medsur.org/age/18_24\")\n",
    "    \n",
    "    if agegroup:\n",
    "        g.add((agegroup, RDF.type, EX.AgeGroup))\n",
    "        g.add((patient, EX.hasAgeGroup, agegroup))\n",
    "\n",
    "    if row[\"sex\"] == \"male\" or row[\"sex\"] == \"female\":\n",
    "        gender = URIRef(f\"http://www.medsur.org/gender/{row['sex']}\")\n",
    "        g.add((gender, RDF.type, EX.Gender))\n",
    "        g.add((patient, EX.hasGender, gender))\n",
    "\n",
    "    if row[\"Outcome\"] != \"Unknown\" or row[\"Outcome\"] != np.nan: \n",
    "        outcome = URIRef(f\"http://www.medsur.org/outcome/{row['Outcome']}\")\n",
    "        g.add((outcome, RDF.type, EX.Outcome))\n",
    "        g.add((patient, EX.hasOutcome, outcome))\n",
    "\n",
    "    if row[\"PTCode\"] != np.nan:\n",
    "        symptom = URIRef(f\"http://www.medsur.org/symptom/{row['PTCode']}\")\n",
    "        g.add((symptom, RDF.type, EX.Symptoms))\n",
    "        g.add((patient, EX.hasSymptom, symptom))\n",
    "\n",
    "    if row[\"ATCode\"] != np.nan:\n",
    "        drug = URIRef(f\"http://www.medsur.org/drug/{row['ATCode']}\")              \n",
    "        g.add((drug, RDF.type, EX.Drug))   \n",
    "        g.add((patient, EX.isGivenDrug, drug))\n",
    "\n",
    "    df_sideeffects = data_sideeffects.loc[data_sideeffects['ATCode'] == row[\"ATCode\"]]\n",
    "  \n",
    "    for index, row2 in df_sideeffects.iterrows():\n",
    "        \n",
    "        if row2[\"PTCode\"] != np.nan:\n",
    "            side_effect = URIRef(f\"http://www.medsur.org/side_effect/{row2['PTCode']}\")\n",
    "            g.add((side_effect, RDF.type, EX.SideEffects))\n",
    "            g.add((drug, EX.hasSideEffect, side_effect))\n",
    "                \n",
    "            # check if any side_effect is present in patient file\n",
    "            if row['is_sideeffect'] == True:\n",
    "                g.add((patient, EX.suffersSideEffect, side_effect))                           \n",
    "                \n",
    "            if row2[\"Frequency\"] != np.nan:\n",
    "                g.add((side_effect, EX.hasFrequency, Literal(row2['Frequency'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the triples in the graph \n",
    "for s, p, o in g:\n",
    "    print(s, p, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = rdflib_to_networkx_digraph(g)\n",
    "print(\"Number of Nodes: {n}\".format(n=nx.number_of_nodes(nx_graph)))\n",
    "print(\"Number of Edges: {n}\".format(n=nx.number_of_edges(nx_graph)))\n",
    "print(\"Density of Graph: {n}\".format(n=nx.density(nx_graph)))\n",
    "print(\"Clustering coefficient: {n}\".format(n=nx.average_clustering(nx_graph)))\n",
    "print(\"Degree centrality:\", nx.degree_centrality(nx_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histdegree = pd.DataFrame(nx.degree_histogram(nx_graph))\n",
    "degree = dict(nx.degree(nx_graph))\n",
    "\n",
    "mean_degree = np.mean(list(degree.values()))\n",
    "mean_degree_centrality = np.mean(list(nx.degree_centrality(nx_graph).values()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6)) \n",
    "ax.bar(histdegree.index.values,histdegree[0])\n",
    "\n",
    "plt.title(\"Mean Degree: {n1}\\n Mean Degree Centrality: {n2}\".format(n1=mean_degree,n2=mean_degree_centrality))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the triples in a csv file\n",
    "with open('medsur.csv', 'w') as f: \n",
    "    for s, p, o in g:\n",
    "        f.write(f'{s},{p},{o} \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
