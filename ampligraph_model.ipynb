{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ampligraph.datasets import load_wn18\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
    "from ampligraph.evaluation import mrr_score, hits_at_n_score\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "import tensorflow as tf\n",
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import re\n",
    "from scipy.special import expit\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             subject  \\\n",
      "0           http://www.medsur.org/patient_NLLRB13960   \n",
      "1          http://www.medsur.org/patient_NLLRB152302   \n",
      "2           http://www.medsur.org/patient_NLLRB51203   \n",
      "3            http://www.medsur.org/patient_NLLRB9515   \n",
      "4  http://www.medsur.org/patient_NLGRUNENTHAL2014...   \n",
      "\n",
      "                                         predicate  \\\n",
      "0  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "1  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "2  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "3  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "4  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "\n",
      "                                       object  \n",
      "0  http://www.medsur.org/side_effect/10062226  \n",
      "1  http://www.medsur.org/side_effect/10024264  \n",
      "2  http://www.medsur.org/side_effect/10046798  \n",
      "3  http://www.medsur.org/side_effect/10061182  \n",
      "4  http://www.medsur.org/side_effect/10040979  \n"
     ]
    }
   ],
   "source": [
    "# load csv medsur.csv\n",
    "colnames = [\"subject\", \"predicate\", \"object\"]\n",
    "triples_df = pd.read_csv('medsur.csv', names=colnames, header=None)\n",
    "triples_df['object'] = triples_df['object'].str.rstrip()\n",
    "\n",
    "print(triples_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             subject  \\\n",
      "0           http://www.medsur.org/patient_NLLRB13960   \n",
      "1          http://www.medsur.org/patient_NLLRB152302   \n",
      "2           http://www.medsur.org/patient_NLLRB51203   \n",
      "3            http://www.medsur.org/patient_NLLRB9515   \n",
      "4  http://www.medsur.org/patient_NLGRUNENTHAL2014...   \n",
      "\n",
      "                                         predicate  \\\n",
      "0  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "1  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "2  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "3  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "4  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "\n",
      "                                       object  \n",
      "0  http://www.medsur.org/side_effect/10062226  \n",
      "1  http://www.medsur.org/side_effect/10024264  \n",
      "2  http://www.medsur.org/side_effect/10046798  \n",
      "3  http://www.medsur.org/side_effect/10061182  \n",
      "4  http://www.medsur.org/side_effect/10040979  \n"
     ]
    }
   ],
   "source": [
    "# only select triples that containt the predicate 'has_outcome'\n",
    "# triples_df = triples_df[triples_df['predicate'] == 'http://example.org/medsur.rdf#hasOutcome']\n",
    "triples_df = triples_df[:100000]\n",
    "print(triples_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '03', '0463', ..., 'rare', 'uncommon', 'veryrare'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create np array of triples [[row1], [row2], ...]\n",
    "triples = triples_df.values\n",
    "entities = np.unique(np.concatenate([triples[:, 0], triples[:, 2]]))\n",
    "entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  (90000, 3)\n",
      "Test set size:  (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "test_size = int(0.1*len(triples_df))\n",
    "\n",
    "X_train, X_test = train_test_split_no_unseen(triples, test_size=test_size)\n",
    "#X_train, X_valid = train_test_split_no_unseen(X_train_valid, test_size=test_size)\n",
    "\n",
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_test.shape)\n",
    "#print('Validation set size: ', X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features.models import ScoringBasedEmbeddingModel as model_embedding\n",
    "\n",
    "# Initialize a ComplEx neural embedding model: the embedding size is k,\n",
    "# eta specifies the number of corruptions to generate per each positive,\n",
    "# scoring_type determines the scoring function of the embedding model.\n",
    "model = ScoringBasedEmbeddingModel(k=150,\n",
    "                                   eta=10,\n",
    "                                   scoring_type='ComplEx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, loss and regularizer definition\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = get_loss('pairwise', {'margin': 0.5})\n",
    "regularizer = get_regularizer('LP', {'p': 2, 'lambda': 1e-5})\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              entity_relation_regularizer=regularizer,\n",
    "              entity_relation_initializer='glorot_uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 44999.4297\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 44959.4766\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 44881.6523\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 44700.7773\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 44300.0664\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 43502.8281\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 42075.5039\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 39741.7734\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 36542.7500\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 33422.4023\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 30721.9570\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 28413.3965\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 26425.8652\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 24701.3398\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 23190.3926\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 21855.7617\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 20668.9551\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 19608.0840\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 18653.7480\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 11s 988ms/step - loss: 17791.0586\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 17007.1445\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 16292.0371\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 15637.6484\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 15035.5195\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 14480.8271\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 13967.6836\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 13490.6045\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 13047.2646\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 12633.4395\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 12246.7734\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 11884.1143\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 11543.5273\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 11222.9209\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 10920.6680\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 10635.0029\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 10365.0029\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 10109.3164\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 9866.9150\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 9636.6279\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 9417.5166\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 9208.8604\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 9009.5820\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 8819.1543\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 8637.7432\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 8463.7764\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 8297.3516\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 8137.8989\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 7985.0000\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 7838.1885\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 7696.8242\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 7560.9473\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 7430.1938\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 7304.1597\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 7182.8691\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 7065.8438\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 6953.0566\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6843.9780\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 6738.4609\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6636.5107\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6537.7036\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6442.3872\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6349.8564\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 6260.2725\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 6173.3472\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 6088.8525\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 6007.1455\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5927.8296\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5850.7461\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5775.8193\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5702.9141\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5632.0679\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5563.2573\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5496.0938\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 14s 1s/step - loss: 5430.7515\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 5367.1592\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 5305.1294\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5244.7930\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5185.9097\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5128.3369\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 5072.3096\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5017.6597\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 10s 932ms/step - loss: 4964.3105\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 10s 909ms/step - loss: 4912.2769\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 4861.5024\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 4811.7915\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 11s 985ms/step - loss: 4763.1484\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 11s 973ms/step - loss: 4715.5684\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 4669.1143\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 4623.6455\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 11s 994ms/step - loss: 4579.1895\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 11s 996ms/step - loss: 4535.5952\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 11s 988ms/step - loss: 4492.9199\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 11s 965ms/step - loss: 4451.1479\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 10s 911ms/step - loss: 4410.3477\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 10s 902ms/step - loss: 4370.4180\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 10s 902ms/step - loss: 4331.3125\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 11s 977ms/step - loss: 4292.9800\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 4255.3481\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 4218.4863\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 4182.3921\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 4146.9199\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 4112.1206\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 4078.0649\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 4044.5562\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 11s 970ms/step - loss: 4011.7300\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3979.5020\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3947.9187\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3916.9309\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3886.4849\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3856.5073\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3827.1008\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3798.1826\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3769.7703\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3741.8811\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3714.3975\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 11s 1000ms/step - loss: 3687.4573\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3660.8428\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 11s 997ms/step - loss: 3634.7874\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3609.1592\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3583.8054\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 11s 985ms/step - loss: 3558.9988\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 10s 907ms/step - loss: 3534.4915\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 11s 967ms/step - loss: 3510.4756\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3486.7878\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3463.4507\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3440.5007\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3417.9858\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3395.7063\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3373.7961\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3352.2827\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3331.0542\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3310.1382\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 3289.5159\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3269.2449\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3249.1697\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3229.4199\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3210.0186\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3190.8066\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3171.8254\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3153.2893\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3134.9214\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3116.7390\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3098.8674\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3081.2046\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3063.8301\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3046.6487\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 3029.7446\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 3013.0342\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 11s 988ms/step - loss: 2996.5208\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 11s 996ms/step - loss: 2980.2612\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2964.1833\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2948.2729\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 10s 914ms/step - loss: 2932.6775\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 10s 909ms/step - loss: 2917.2222\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2901.9216\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2886.8142\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2871.9131\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2857.2344\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2842.6802\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2828.3430\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2814.2017\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2800.1562\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2786.3179\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2772.6675\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2759.1460\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 13s 1s/step - loss: 2745.8943\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2732.7139\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2719.7256\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2706.8696\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2694.1147\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2681.5459\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2669.1311\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2656.8418\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2644.7563\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2632.7639\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 11s 956ms/step - loss: 2620.9353\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 10s 938ms/step - loss: 2609.2122\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2597.5425\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 11s 963ms/step - loss: 2586.0671\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 11s 957ms/step - loss: 2574.7104\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 11s 1s/step - loss: 2563.4451\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 10s 945ms/step - loss: 2552.2910\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 10s 939ms/step - loss: 2541.2986\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 10s 945ms/step - loss: 2530.4673\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 10s 939ms/step - loss: 2519.6702\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 10s 934ms/step - loss: 2508.9939\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 10s 947ms/step - loss: 2498.4768\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 10s 938ms/step - loss: 2488.0681\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 10s 945ms/step - loss: 2477.8062\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 10s 950ms/step - loss: 2467.5664\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 11s 976ms/step - loss: 2457.4797\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 11s 974ms/step - loss: 2447.5088\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 11s 955ms/step - loss: 2437.6016\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 11s 979ms/step - loss: 2427.7959\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 10s 928ms/step - loss: 2418.0913\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 11s 969ms/step - loss: 2408.5051\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 10s 936ms/step - loss: 2399.0344\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 10s 941ms/step - loss: 2389.6326\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 10s 949ms/step - loss: 2380.3667\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 10s 939ms/step - loss: 2371.1528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x239037241c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on training and validation set\n",
    "model.fit(X_train,\n",
    "          # use 1/10 of the training set as batch size\n",
    "          batch_size=int(X_train.shape[0] / 10),\n",
    "          epochs=200,                    # Number of training epochs\n",
    "          verbose=True                  # Enable stdout messages\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation procedure on the test set (with filtering)\n",
    "# To disable filtering: use_filter=None\n",
    "# Usually, we corrupt subject and object sides separately and compute ranks\n",
    "\n",
    "positives_filter = {'test': np.concatenate([X_train, X_test])}\n",
    "ranks = model.evaluate(X_test,\n",
    "                       use_filter=positives_filter,   # Corruption strategy filter defined above\n",
    "                       corrupt_side='s,o',  # corrupt subj and obj separately while evaluating\n",
    "                       verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.14\n",
      "Hits@10: 0.19\n",
      "Hits@3: 0.15\n",
      "Hits@1: 0.10\n"
     ]
    }
   ],
   "source": [
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.2f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.2f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.2f\" % (hits_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path ./best_model.pkl already exists. This save operation will overwrite the model                 at the specified path.\n",
      "WARNING - Found untraced functions such as _get_ranks while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.utils import save_model, restore_model\n",
    "save_model(model, './best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model does not include a db file. Skipping.\n",
      "The model is fit!\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = restore_model('./best_model.pkl')\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             subject  \\\n",
      "0           http://www.medsur.org/patient_NLLRB13960   \n",
      "1          http://www.medsur.org/patient_NLLRB152302   \n",
      "2           http://www.medsur.org/patient_NLLRB51203   \n",
      "3            http://www.medsur.org/patient_NLLRB9515   \n",
      "4  http://www.medsur.org/patient_NLGRUNENTHAL2014...   \n",
      "\n",
      "                                         predicate  \\\n",
      "0  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "1  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "2  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "3  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "4  http://example.org/medsur.rdf#suffersSideEffect   \n",
      "\n",
      "                                       object  \n",
      "0  http://www.medsur.org/side_effect/10062226  \n",
      "1  http://www.medsur.org/side_effect/10024264  \n",
      "2  http://www.medsur.org/side_effect/10046798  \n",
      "3  http://www.medsur.org/side_effect/10061182  \n",
      "4  http://www.medsur.org/side_effect/10040979  \n",
      "(100000, 3)\n",
      "(1710, 3)\n"
     ]
    }
   ],
   "source": [
    "def link_prediction(cluster):\n",
    "\n",
    "    # get all unique outcomes\n",
    "    outcomes = []\n",
    "    for subject, predicate, object in triples_df.values:\n",
    "        if predicate == 'http://example.org/medsur.rdf#hasOutcome':\n",
    "            outcomes.append(object)\n",
    "    outcomes = np.unique(outcomes)\n",
    "\n",
    "    X_unseen = np.array([])\n",
    "\n",
    "    for subject, predicate, object in triples_df.values:\n",
    "        \n",
    "        # find all predicates for subject\n",
    "        if re.search('http://example.org/medsur.rdf#Patients', object): \n",
    "            predicates = triples_df.loc[triples_df['subject'] == subject, 'predicate'].unique()\n",
    "            \n",
    "            # check if predicates hasoutcome is present\n",
    "            if 'http://example.org/medsur.rdf#hasOutcome' not in predicates:\n",
    "                \n",
    "                # add triple (subject, hasOutcome, outcome) for all outcomes\n",
    "                for outcome in outcomes:\n",
    "                    \n",
    "                    # append to X_unseen in format [[subject, hasOutcome, outcome]] with dimensions (n, 3)\n",
    "                    X_unseen = np.append(X_unseen, np.array([[subject, 'http://example.org/medsur.rdf#hasOutcome', outcome]]))\n",
    "                    \n",
    "    # reshape to (n, 3)\n",
    "    X_unseen = X_unseen.reshape(int(len(X_unseen)/3), 3)\n",
    "    \n",
    "    ranks_unseen = model.evaluate(X_unseen,\n",
    "                              use_filter=positives_filter,   # Corruption strategy filter defined above\n",
    "                              corrupt_side='s+o',\n",
    "                              verbose=True)\n",
    "    \n",
    "    scores = model.predict(X_unseen)\n",
    "    probs = expit(scores)\n",
    "    \n",
    "    df_ranking = pd.DataFrame(list(zip([' '.join(x) for x in X_unseen],\n",
    "                                   ranks_unseen,\n",
    "                                   np.squeeze(scores),\n",
    "                                   np.squeeze(probs))),\n",
    "                          columns=['statement', 'rank', 'score', 'prob']).sort_values(\"score\", ascending=False)\n",
    "\n",
    "    df_ranking.head(10)\n",
    "    \n",
    "    # split dataframe into 4 dataframes based on outcome\n",
    "    results = {}\n",
    "    for outcome in outcomes:\n",
    "        df_outcome = df_ranking.loc[df_ranking['statement'].str.contains(outcome)]\n",
    "        # reset index\n",
    "        df_outcome = df_outcome.reset_index(drop=True)\n",
    "        print(df_outcome.head(10))\n",
    "\n",
    "        # get mean value of score and prob\n",
    "        mean_score = df_outcome['score'].mean()\n",
    "        mean_prob = df_outcome['prob'].mean()\n",
    "\n",
    "        # only select last part of word (after last /) in outcome\n",
    "        outcome = (outcome.split('/')[-1]).lower()\n",
    "        if outcome == \"resolved_with_sequelae\":\n",
    "            outcome = \"rws\"\n",
    "        results[outcome] = {'score': mean_score, 'probability': mean_prob}\n",
    "\n",
    "    # create barplot of mean score and mean prob for each outcome with seaborn\n",
    "    df_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "    plt.pyplot.figure(figsize=(10, 5))\n",
    "    plt.pyplot.title('Mean score for each outcome')\n",
    "\n",
    "    # plot error bars\n",
    "    sns.barplot(x=df_results.index,\n",
    "                y=df_results['score'], yerr=df_results['score'].std())\n",
    "\n",
    "\n",
    "    plt.pyplot.figure(figsize=(10, 5))\n",
    "    plt.pyplot.title('Mean probability for each outcome')\n",
    "    sns.barplot(x=df_results.index,\n",
    "                y=df_results['probability'], yerr=df_results['probability'].std())\n",
    "    \n",
    "    return df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from triples\n",
    "triples_df = pd.DataFrame(triples, columns=['subject', 'predicate', 'object'])\n",
    "df_ranking = link_prediction(triples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 26s 187ms/step\n",
      "                                              statement   rank     score  \\\n",
      "2729  http://www.medsur.org/patient_NLSZ09PHHO2015NL...   [17]  1.731812   \n",
      "2225  http://www.medsur.org/patient_NLGRUNENTHAL2020...   [19]  1.651481   \n",
      "89    http://www.medsur.org/patient_NLTEVA413627ISR ...   [25]  1.594398   \n",
      "197   http://www.medsur.org/patient_NLAPOTEX2016AP00...   [36]  1.444023   \n",
      "1037  http://www.medsur.org/patient_NLLRB15267 http:...   [47]  1.392875   \n",
      "209   http://www.medsur.org/patient_NLGRUNENTHAL2014...   [49]  1.371838   \n",
      "1877  http://www.medsur.org/patient_NLLRB66415 http:...   [55]  1.338632   \n",
      "130   http://www.medsur.org/patient_NLGRUNENTHAL2009...  [296]  1.287760   \n",
      "21    http://www.medsur.org/patient_NLLRB72171 http:...    [4]  1.286279   \n",
      "2129  http://www.medsur.org/patient_NLLRB30253 http:...   [63]  1.283777   \n",
      "\n",
      "          prob  \n",
      "2729  0.849644  \n",
      "2225  0.839091  \n",
      "89    0.831234  \n",
      "197   0.809077  \n",
      "1037  0.801051  \n",
      "209   0.797677  \n",
      "1877  0.792265  \n",
      "130   0.783768  \n",
      "21    0.783517  \n",
      "2129  0.783092  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_drug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-115a8e0ae5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdrug\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdrugs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mdf_drug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ranking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_drug\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m# reset index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdf_drug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_drug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_drug' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: create groups of patients bases on side-effect clusters\n",
    "# dus bv groep 1 suffersfrom sideeffects uit cluster 1, groep 2 suffersfrom sideeffects uit cluster 2, etc\n",
    "triples_df = pd.DataFrame(triples, columns=['subject', 'predicate', 'object'])\n",
    "X_unseen = np.array([])\n",
    "\n",
    "drugs = []\n",
    "for subject, predicate, object in triples_df.values:\n",
    "    if predicate == 'http://example.org/medsur.rdf#isGivenDrug':\n",
    "        drugs.append(object)\n",
    "drugs = np.unique(drugs)\n",
    "\n",
    "for subject, predicate, object in triples_df.values:\n",
    "    \n",
    "    # check if subject is patient\n",
    "    if re.search('http://example.org/medsur.rdf#Patients', object): \n",
    "        \n",
    "        # add triple (subject, hasOutcome, outcome) for all outcomes\n",
    "        for drug in drugs:\n",
    "            # append to X_unseen in format [[subject, hasOutcome, outcome]] with dimensions (n, 3)\n",
    "            X_unseen = np.append(X_unseen, np.array([[subject, 'http://example.org/medsur.rdf#isGivenDrug', drug]]))\n",
    "\n",
    "# reshape to (n, 3)\n",
    "X_unseen = X_unseen.reshape(int(len(X_unseen)/3), 3)\n",
    "\n",
    "ranks_unseen = model.evaluate(X_unseen,\n",
    "                              use_filter=positives_filter,   # Corruption strategy filter defined above\n",
    "                              corrupt_side='s+o',\n",
    "                              verbose=True)\n",
    "scores = model.predict(X_unseen)\n",
    "probs = expit(scores)\n",
    "\n",
    "df_ranking = pd.DataFrame(list(zip([' '.join(x) for x in X_unseen],\n",
    "                                   ranks_unseen,\n",
    "                                   np.squeeze(scores),\n",
    "                                   np.squeeze(probs))),\n",
    "                          columns=['statement', 'rank', 'score', 'prob']).sort_values(\"score\", ascending=False)\n",
    "\n",
    "print(df_ranking.head(10))\n",
    "\n",
    "# split dataframe into 4 dataframes based on outcome\n",
    "results = {}\n",
    "\n",
    "for drug in drugs:\n",
    "    df_drug = df_ranking.loc[df_ranking['statement'].str.contains(drug)]\n",
    "    # reset index\n",
    "    df_drug = df_drug.reset_index(drop=True)\n",
    "    print(df_drug.head(10))\n",
    "    # get mean value of score and prob\n",
    "    mean_score = df_drug['score'].mean()\n",
    "    mean_prob = df_drug['prob'].mean()\n",
    "\n",
    "    # only select last part of word (after last /) in outcome\n",
    "    drug = (drug.split('/')[-1]).lower()\n",
    "    results[drug] = {'score': mean_score, 'probability': mean_prob}\n",
    "\n",
    "# create barplot of mean score and mean prob for each outcome with seaborn\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "plt.pyplot.figure(figsize=(10, 5))\n",
    "plt.pyplot.title('Mean score for each side effect')\n",
    "\n",
    "# plot error bars\n",
    "sns.barplot(x=df_results.index,\n",
    "            y=df_results['score'], yerr=df_results['score'].std())\n",
    "\n",
    "\n",
    "plt.pyplot.figure(figsize=(10, 5))\n",
    "plt.pyplot.title('Mean probability for each side effect')\n",
    "sns.barplot(x=df_results.index,\n",
    "            y=df_results['probability'], yerr=df_results['probability'].std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2967556ad1cc0b07d108fdcc876ab0a44458be2f8a9d1ccef00065e78f2b8f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
